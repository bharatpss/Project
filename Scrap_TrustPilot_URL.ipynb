{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "#Thrown when element could not be found.\n",
    "\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "#Thrown when a command does not complete in enough time.\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "# Set of supported locator strategies.\n",
    "\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://www.trustpilot.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url):\n",
    "#     BeautifulSoup(requests.get(base_url).content, 'html.parser')\n",
    "    return BeautifulSoup(requests.get(url).content, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from webdriver_manager.chrome import ChromeDriverManager\n",
    "# driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "# driver.get(base_url)\n",
    "# driver.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "soup = get_soup(base_url+ '/categories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = {}\n",
    "# a['ayush'] = {}\n",
    "# a['ayush']['pratap']='bharat'\n",
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in soup.findAll('div', {'class': 'subCategory___BRUDy'}):\n",
    "    name = category.find('h3', {'class':'subCategoryHeader___36ykD'}).text\n",
    "    name = name.strip()#Return a copy of the string with leading and trailing whitespace remove.\n",
    "    data[name] = {}\n",
    "    sub_categories = category.find('div', {'class': 'subCategoryList___r67Qj'})\n",
    "#     print(category.find('div', {'class':'subCategoryItem___3ksKz'}))\n",
    "#     print(sub_categories)\n",
    "    for sub_category in sub_categories.findAll('div', {'class': 'subCategoryItem___3ksKz'}):\n",
    "        sub_category_name = sub_category.find('a', {'class': 'navigation___2Efid'}).text \n",
    "        sub_category_uri = sub_category.find('a', {'class': 'navigation___2Efid'})['href'] \n",
    "        data[name][sub_category_name] = sub_category_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('start-maximized')\n",
    "options.add_argument('disable-infobars')\n",
    "options.add_argument(\"--disable-extensions\")\n",
    "\n",
    "prefs = {\"profile.managed_default_content_settings.images\": 2}\n",
    "options.add_experimental_option(\"prefs\", prefs)\n",
    "# This prevents Selenium from opening up a Chrome window thus accelerating the scraping.\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install(), options=options)\n",
    "\n",
    "# driver = webdriver.Chrome('./driver/chromedriver', options=options)\n",
    "# driver = webdriver.Chrome('C:/Users/BHARAT PRATAP/.wdm/chromedriver/81.0.4044.138/win32/chromedriver', options=options)\n",
    "\n",
    "timeout = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "s = 'https://www.trustpilot.com/review/pawprintgenetics.com'\n",
    "\n",
    "'review' in re.findall(r'\\w+', s)\n",
    "# re.findall(r'\\w+:/{2}\\w+.\\w+.\\w+/{1}\\w+', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data['Animals & Pets']['Animal Health']\n",
    "# driver.get('https://www.trustpilot.com/categories/ball_games')#base_url+data['Animals & Pets']['Animal Health']+'?numberofreviews=0&timeperiod=0&status=all')\n",
    "# BeautifulSoup(driver.page_source, 'lxml')\n",
    "# l = driver.find_elements_by_xpath('//a[@class=\"wrapper___2rOTx\"]')\n",
    "# [a.get_attribute('href') for a in l if 'review' in re.findall(r'\\w+', a.get_attribute('href'))]\n",
    "# # l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_company_urls_form_page():\n",
    "    a_list = driver.find_elements_by_xpath('//a[@class=\"wrapper___2rOTx\"]')\n",
    "    URLs = [a.get_attribute('href') for a in a_list if 'review' in re.findall(r'\\w+', a.get_attribute('href'))]\n",
    "    dedup_urls = list(set(URLs))\n",
    "    return dedup_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def go_next_page():\n",
    "    try:\n",
    "        button = driver.find_element_by_xpath('//a[@class=\"paginationLinkNormalize___scOgG paginationLinkNext___1LQ14\"]')\n",
    "        return True, button\n",
    "    except NoSuchElementException:\n",
    "        return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.get('Animals & Pets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_urls = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url + data['Animals & Pets']['Animal Health']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for category in tqdm_notebook(data):\n",
    "for sub_category in tqdm_notebook(data['Animals & Pets'], leave=False):\n",
    "    company_urls[sub_category] = []\n",
    "    url = base_url + data['Animals & Pets'][sub_category]\n",
    "    driver.get(url)\n",
    "#         try:\n",
    "#             element = EC.presence_of_element_located((By.CLASS_NAME, 'wrapper___2rOTx'))\n",
    "#             WebDriverWait(driver, timeout).until(element)\n",
    "#         except:\n",
    "#             pass\n",
    "#         next_page = True\n",
    "    c = 1\n",
    "    while c<=5:#next_page:\n",
    "        extracted_company_urls = extract_company_urls_form_page()\n",
    "        company_urls[sub_category] += extracted_company_urls\n",
    "        next_page, button = go_next_page()\n",
    "        if next_page:\n",
    "            c += 1\n",
    "            next_url = base_url + data['Animals & Pets'][sub_category]+f'?page={c}'\n",
    "            driver.get(next_url)\n",
    "#         print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "company_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_administration_services = pd.DataFrame(company_urls,)\n",
    "\n",
    "# df_administration_services.to_csv('administration_services.CSV', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# company_urls = {}\n",
    "# for category in tqdm_notebook(data):\n",
    "#     for sub_category in tqdm_notebook(data[category], leave=False):\n",
    "#         company_urls[sub_category] = []\n",
    "\n",
    "#         url = base_url + data[category][sub_category] + \"?numberofreviews=0&timeperiod=0&status=all\"\n",
    "#         driver.get(url)\n",
    "#         try: \n",
    "#             element_present = EC.presence_of_element_located(\n",
    "#                 (By.CLASS_NAME, 'wrapper___2rOTx'))\n",
    "            #https://selenium-python.readthedocs.io/waits.html\n",
    "#             WebDriverWait(driver, timeout).until(element_present)\n",
    "#         except:\n",
    "#             pass\n",
    "    \n",
    "#         next_page = True\n",
    "#         c = 1\n",
    "#         while next_page:\n",
    "#             extracted_company_urls = extract_company_urls_form_page()\n",
    "#             company_urls[sub_category] += extracted_company_urls\n",
    "#             next_page, button = go_next_page()\n",
    "            \n",
    "#             if next_page:\n",
    "#                 c += 1\n",
    "#                 next_url = base_url + data[category][sub_category] + \"?numberofreviews=0&timeperiod=0&status=all\" + f'?page={c}'\n",
    "#                 driver.get(next_url)\n",
    "#                 try: \n",
    "#                     element_present = EC.presence_of_element_located(\n",
    "#                         (By.CLASS_NAME, 'wrapper___2rOTx'))\n",
    "                    \n",
    "#                     WebDriverWait(driver, timeout).until(element_present)\n",
    "#                 except:\n",
    "#                     pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consolidated_data = []\n",
    "\n",
    "for category in data:\n",
    "    for sub_category in data[category]:\n",
    "        for url in company_urls[sub_category]:\n",
    "            consolidated_data.append((category, sub_category, url))\n",
    "\n",
    "df_consolidated_data = pd.DataFrame(consolidated_data, columns=['category', 'sub_category', 'company_url'])\n",
    "\n",
    "df_consolidated_data.to_csv('consolidate_company_urls.CSV', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
